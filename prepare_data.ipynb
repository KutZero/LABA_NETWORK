{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d71888-cf1b-403f-93ac-0b5e6720ebfd",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571bf5b-140c-45ca-8341-3c01ab93ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import display\n",
    "#tf.compat.v1.set_random_seed(290)\n",
    "# детерминирование случайных величин\n",
    "tf.random.set_seed(290)\n",
    "np.random.seed(290)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fdc904-4223-481b-af02-d8f845a0fd96",
   "metadata": {},
   "source": [
    "### Скачивание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9988658-fd60-49f1-902a-c99432091ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачать датасет\n",
    "# закомменть после того как скачаешь\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "archive = tf.keras.utils.get_file(origin=dataset_url, extract=True, cache_dir=os.getcwd())\n",
    "data_dir = pathlib.Path(archive).with_suffix('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a21d37-e44e-4e9c-ab59-aeb564bef212",
   "metadata": {},
   "source": [
    "### Разметка данных (изначально в датасете нет размытых изображений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba728c3-118b-40fd-8dbe-84763191ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = 0.60 \n",
    "VAL_PERCENT = 0.20\n",
    "TEST_PERCENT = 0.20\n",
    "\n",
    "IMAGE_WIDTH = 256 # для https://github.com/infernaaa/OIS_FINAL_LABA надо 640на640\n",
    "IMAGE_HEIGHT = 256\n",
    "\n",
    "# folder with random photo without blur or labeling\n",
    "PATH_TO_UNPREPARED_DATASET = 'datasets/flower_photos'\n",
    "# forler where will be stored labeled data\n",
    "PATH_TO_SAVE_DATASET = 'labeled_dataset'\n",
    "\n",
    "dataset = {'train':[],\n",
    "           'val':[],\n",
    "           'test':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314201a-b1c5-4ce9-aa1c-1950bbdaa3fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort all photos to train,val and test datasets (and to sharp and blur ones)\n",
    "# нужно чтобы представители каждого класса из скачанного датасета присутствовали в \n",
    "# каждой выборке\n",
    "for tup in os.walk(PATH_TO_UNPREPARED_DATASET):\n",
    "    # tup - это кортеж 3 элементов\n",
    "    # tup[0] - относительный путь до обрабатываемой папки\n",
    "    # tup[1] - список всех папок в ней\n",
    "    # tup[2] - список всех файлов в ней\n",
    "\n",
    "    # если в папке есть изображения типа jpg\n",
    "    if [filename for filename in tup[2] if filename.endswith('.jpg')]:\n",
    "        print(tup[0], tup[1], len(tup[2]), 'items in current path')\n",
    "        # make every relative path absolute and cast to numpy ndarray\n",
    "        temp_arr = np.array([pathlib.Path(tup[0])/filename for filename in tup[2]])#[:100]\n",
    "        # split ndarray of absolute paths to images to 3 parts by percentage\n",
    "        temp_train, temp_validate, temp_test = np.split(temp_arr, \n",
    "                                                        [int(temp_arr.shape[0]*TRAIN_PERCENT), \n",
    "                                                         int(temp_arr.shape[0]*(TRAIN_PERCENT+VAL_PERCENT))])\n",
    "        # add ndarray to list of each dataset part\n",
    "        # like dataset['train'] = list(np.ndarray(1,2,3), np.ndarray(4,5,6))\n",
    "        dataset['train'].append(temp_train)\n",
    "        dataset['val'].append(temp_validate)\n",
    "        dataset['test'].append(temp_test)\n",
    "\n",
    "# concatenate each numpy ndarray in each dataset part to one ndarray\n",
    "for key, value in dataset.items():\n",
    "    dataset[key] = np.concatenate(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61400479-79d1-4cb5-93dc-da5357380abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print dataset info\n",
    "for key, value in dataset.items():\n",
    "    print('|'*8,f'{key} part','|'*8)\n",
    "    print(f'\\tTotal items: {value.shape[0]}')\n",
    "    print(f'\\tExample (first 2 items):',*value[:2],sep='\\n\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f870259-c25a-4f67-ab46-30862fb0e552",
   "metadata": {},
   "source": [
    "### Обработка размеченных данных (применение размытия) и помощение в новую папку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15f5f4-c8ad-4994-8025-1dce73bd7929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "# blur labeled images and put all images in new folders\n",
    "for key, value in dataset.items():\n",
    "    # create path to save new photo\n",
    "    path_to_save_blur =  pathlib.Path(PATH_TO_SAVE_DATASET)/key/'blur'\n",
    "    if not os.path.exists(path_to_save_blur):\n",
    "        os.makedirs(path_to_save_blur)\n",
    "        \n",
    "    path_to_save_sharp =  pathlib.Path(PATH_TO_SAVE_DATASET)/key/'sharp'\n",
    "    if not os.path.exists(path_to_save_sharp):\n",
    "        os.makedirs(path_to_save_sharp)\n",
    "\n",
    "    for image_path in value:\n",
    "        filename = image_path.name\n",
    "        \n",
    "        img = keras.utils.load_img(image_path)\n",
    "        img = keras.utils.img_to_array(img)\n",
    "        img = keras.layers.Resizing(IMAGE_HEIGHT, IMAGE_WIDTH)(img)\n",
    "        img = keras.utils.array_to_img(img)\n",
    "        img.save(path_to_save_sharp / filename)\n",
    "\n",
    "        filename = \"blur_\"+filename\n",
    "        \n",
    "        img = img.filter(ImageFilter.BLUR)\n",
    "        img.save(path_to_save_blur / filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d819b3be-70b5-40cb-91c1-481e85794254",
   "metadata": {},
   "source": [
    "### Как добавить имена новых изображение к старому csv файлу из https://github.com/infernaaa/OIS_FINAL_LABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b156f-5557-4cda-b289-2771431d3e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# все имена файлов из только что размеченного датасета в датафрейме\n",
    "# стобцы filenama,dataset,blur\n",
    "# filename = путь к изображению\n",
    "# dataset = train, test или val (к какому датасету относится изображение)\n",
    "# blur = 0 или 1 (заблюрено ли изображение)\n",
    "\n",
    "dataset_df = pd.DataFrame(data=list(pathlib.Path(PATH_TO_SAVE_DATASET).rglob('*.jpg')), columns=['filename'])\n",
    "dataset_df['dataset'] = dataset_df['filename'].map(lambda x: x.parent.parent.stem)\n",
    "dataset_df['blur'] = dataset_df['filename'].map(lambda x: 1 if x.parent.stem=='blur' else 0)\n",
    "\n",
    "# весь датасет в 1 датафрейме\n",
    "display(dataset_df)\n",
    "# только размытые изображения\n",
    "#display(dataset_df[dataset_df['blur']==1].shape)\n",
    "# только четкие изображения\n",
    "#display(dataset_df[dataset_df['blur']==0].shape)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c98c66-e0f4-4429-b74f-8efdf1c9e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# привести датафрейм к виду как в  https://github.com/infernaaa/OIS_FINAL_LABA с 2 колонками\n",
    "# train, test и val надо класть в отдельные датафреймы\n",
    "train_df = dataset_df[dataset_df['dataset']=='train']\n",
    "train_df = train_df.drop(['dataset'],axis=1)\n",
    "train_df['filename'] = train_df['filename'].map(lambda x: x.name)\n",
    "\n",
    "test_df = dataset_df[dataset_df['dataset']=='test']\n",
    "test_df = test_df.drop(['dataset'],axis=1)\n",
    "test_df['filename'] = test_df['filename'].map(lambda x: x.name)\n",
    "\n",
    "display(train_df)\n",
    "display(test_df)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1d719-1666-4e26-af5d-7f1bd4defabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# прочитать оригинальный csv файл из https://github.com/infernaaa/OIS_FINAL_LABA как датафрейм\n",
    "path_to_train = pathlib.Path('') # путь как str или pathlib.Path()\n",
    "path_to_test = pathlib.Path('')\n",
    "old_train = pd.read_csv(path_to_train)\n",
    "old_test = pd.read_csv(path_to_train)\n",
    "\n",
    "# объединить имена новых фото со старыми\n",
    "new_train = pd.concat([train_df, old_train], axis=0, ignore_index=True)\n",
    "new_test = pd.concat([test_df, old_test], axis=0, ignore_index=True)\n",
    "\n",
    "# вывести объединенные датафереймы\n",
    "display(new_train)\n",
    "display(new_test)\n",
    "\n",
    "# сохранить как csv\n",
    "new_train.to_csv(f'{PATH_TO_SAVE_DATASET}/train/new_train.csv')\n",
    "new_test.to_csv(f'{PATH_TO_SAVE_DATASET}/test/new_test.csv')\n",
    "\n",
    "# а вот сами фото в папки в https://github.com/infernaaa/OIS_FINAL_LABA надо ручками перенести\n",
    "# как и новые файлы csv которыми надо заменить старые \n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5bab9-3005-42a3-887d-0acc27b471c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
