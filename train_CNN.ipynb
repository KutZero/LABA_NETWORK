{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d71888-cf1b-403f-93ac-0b5e6720ebfd",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f84886-af81-4f74-91e5-0e3b8bd96483",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install matplotlib \n",
    "!pip install pydot \n",
    "!pip install graphviz \n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8b320-22b9-48b6-ba66-99814ed5674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from PIL import Image, ImageFilter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3795e770-a437-4426-95be-c844b416cb04",
   "metadata": {},
   "source": [
    "### Загрузка датасета (на примере обработанного датасета \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad0b26-7d24-4819-bfb3-bf76d72d9729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачать датасет\n",
    "# закомменть после того как скачаешь\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "archive = tf.keras.utils.get_file(origin=dataset_url, extract=True, cache_dir=os.getcwd())\n",
    "data_dir = pathlib.Path(archive).with_suffix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae732d50-ddc0-4c8c-9ac3-68ae61e465f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тоотношения тренировочной, валидационной и тестовой выборки\n",
    "TRAIN_PERCENT = 0.60 \n",
    "VAL_PERCENT = 0.20\n",
    "TEST_PERCENT = 1 - TRAIN_PERCENT - VAL_PERCENT\n",
    "\n",
    "if (TRAIN_PERCENT + VAL_PERCENT + TEST_PERCENT) != 1.:\n",
    "    raise ValueError('Сумма процентов должна быть равна 1')\n",
    "\n",
    "# папка в которую загрузится датасет flower_photos от tensorflow.org\n",
    "PATH_TO_UNPREPARED_DATASET = 'datasets/flower_photos.tgz/flower_photos'\n",
    "# папка в которой будет храниться готовый датасет после предобработки\n",
    "PATH_TO_SAVE_DATASET = 'labeled_dataset'\n",
    "\n",
    "# если поменять результат обучения измениться\n",
    "# детерминирование случайных величин\n",
    "SEED = 290\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "DATASET_PATH = pathlib.Path(PATH_TO_SAVE_DATASET)\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "\n",
    "# словарь содержащий пути к фото для разных выборок\n",
    "dataset = {'train':[],\n",
    "           'val':[],\n",
    "           'test':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb66c02-a712-4936-8aa1-6adda99b1387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# распределяет все фото по тренировочному, валидационному и тестовому датасету\n",
    "# нужно чтобы представители каждого класса из скачанного датасета присутствовали в \n",
    "# каждой выборке\n",
    "for tup in os.walk(PATH_TO_UNPREPARED_DATASET):\n",
    "    # tup - это кортеж 3 элементов\n",
    "    # tup[0] - относительный путь до обрабатываемой папки\n",
    "    # tup[1] - список всех папок в ней\n",
    "    # tup[2] - список всех файлов в ней\n",
    "\n",
    "    # если в папке есть изображения типа jpg\n",
    "    if [filename for filename in tup[2] if filename.endswith('.jpg')]:\n",
    "        print(f'Путь к фоторафиям: {tup[0]}. Кол-во фото в папке: {len(tup[2])}')\n",
    "        # получить относительный путь ко всем фото в папке\n",
    "        temp_arr = np.array([pathlib.Path(tup[0])/filename for filename in tup[2]])\n",
    "        # разделить список путей к фото на 3 части для каждой выборки\n",
    "        temp_train, temp_validate, temp_test = np.split(temp_arr, \n",
    "                                                        [int(temp_arr.shape[0]*TRAIN_PERCENT), \n",
    "                                                         int(temp_arr.shape[0]*(TRAIN_PERCENT+VAL_PERCENT))])\n",
    "        # add ndarray to list of each dataset part\n",
    "        # like dataset['train'] = list(np.ndarray(1,2,3), np.ndarray(4,5,6))\n",
    "        dataset['train'].append(temp_train)\n",
    "        dataset['val'].append(temp_validate)\n",
    "        dataset['test'].append(temp_test)\n",
    "\n",
    "# concatenate each numpy ndarray in each dataset part to one ndarray\n",
    "for key, value in dataset.items():\n",
    "    dataset[key] = np.concatenate(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1881b3-c547-4d42-bbe0-5721cbfebcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataset info\n",
    "for key, value in dataset.items():\n",
    "    print('|'*8,f'{key} выборка','|'*8)\n",
    "    print(f'\\tКол-во наблюдений: {value.shape[0]}')\n",
    "    print(f'\\Пример путей к фото (первые два):',*value[:2],sep='\\n\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a94b2a-a242-4db5-8530-8f2f6b6e6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur labeled images and put all images in new folders\n",
    "for key, value in dataset.items():\n",
    "    # create path to save new photo\n",
    "    path_to_save_blur =  pathlib.Path(PATH_TO_SAVE_DATASET)/key/'blur'\n",
    "    if not os.path.exists(path_to_save_blur):\n",
    "        os.makedirs(path_to_save_blur)\n",
    "        \n",
    "    path_to_save_sharp =  pathlib.Path(PATH_TO_SAVE_DATASET)/key/'sharp'\n",
    "    if not os.path.exists(path_to_save_sharp):\n",
    "        os.makedirs(path_to_save_sharp)\n",
    "\n",
    "    for image_path in tqdm(value, desc=f'Подготовка данных для {key} выборки'):\n",
    "        filename = image_path.name\n",
    "        \n",
    "        img = keras.utils.load_img(image_path)\n",
    "        img = keras.utils.img_to_array(img)\n",
    "        img = keras.layers.Resizing(IMAGE_HEIGHT, IMAGE_WIDTH)(img)\n",
    "        img = keras.utils.array_to_img(img)\n",
    "        img.save(path_to_save_sharp / filename)\n",
    "\n",
    "        filename = \"blur_\"+filename\n",
    "        \n",
    "        img = img.filter(ImageFilter.BLUR)\n",
    "        img.save(path_to_save_blur / filename)\n",
    "        \n",
    "print('Подготовка завершена')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1d719-1666-4e26-af5d-7f1bd4defabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.preprocessing.image_dataset_from_directory \n",
    "# автоматически делит данные на батчи и размечает данные \n",
    "# как класс blur и sharp на основании структуры переданной папки\n",
    "# В нашем случае передается папка со структурой:\n",
    "# train/\n",
    "#     blur/\n",
    "#         image1.jpg\n",
    "#         image2.jpg\n",
    "#     sharp/\n",
    "#         image1.jpg\n",
    "#         image2.jpg\n",
    "# Изображения класса blur помечаются как 1, класса sharp как 0\n",
    "# tf.keras.preprocessing.image_dataset_from_directory автоматом\n",
    "# приводит все изображения к единому размеру (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH/'train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_format='channels_last',\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH/'val',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_format='channels_last',\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH/'test',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_format='channels_last',\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a61b02-e9a6-4245-9776-997a57afa170",
   "metadata": {},
   "source": [
    "### пример 1 батча наблюдения и его маркировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22473ad-4ce3-4c57-b2b3-ea1e5c01e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_ds))\n",
    "batch_shapes = [x.shape for x in list(train_ds)[0]]\n",
    "\n",
    "# размер входного батча данных (batch_size, rows, cols, challels)\n",
    "print(f'Размер входного батча данных: {batch_shapes[0]}')\n",
    "\n",
    "# размер выходного батча данных (batch_size, num_classes)\n",
    "# если классов 2 (как у нас - blur и sharp), то num_classes равен 1 (ибо 2 класса кодируются 1 числом)\n",
    "print(f'Размер выходного батча данных: {batch_shapes[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77fa955-fb21-487b-adfb-4c69b15652a9",
   "metadata": {},
   "source": [
    "# Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daff3c-4935-44fb-81ba-3f0fc85aed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка шага обучения, метрик, оптимизатора\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "LOSS_FUNCTION = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "OPTIMIZER = keras.optimizers.SGD(LEARNING_RATE)\n",
    "\n",
    "METRICS = [keras.metrics.BinaryAccuracy(name='BinaryAccuracy'), \n",
    "           keras.metrics.MeanSquaredError(name='MeanSquaredError'),\n",
    "           keras.metrics.Precision(name='Precision'),\n",
    "           keras.metrics.Recall(name='Recall'),\n",
    "           keras.metrics.AUC(name='PR_AUC', curve='PR'),\n",
    "           keras.metrics.AUC(name='ROC_AUC', curve='ROC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12f605-4c81-449b-a953-26be3d9d781d",
   "metadata": {},
   "source": [
    "### Блок предобработки изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1d6bf-f484-4183-b227-0e6ddf3fc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пиксели RGB имеют занчения от 0 до 255, этот слой приводит их к диапазону от 0 до 1\n",
    "rescale = tf.keras.Sequential([\n",
    "  layers.Rescaling(1./255)\n",
    "], name='preprocess_part')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c1157f-a379-47fc-a002-a99c12250183",
   "metadata": {},
   "source": [
    "### Блок аугментации изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ab164-0d7d-41d6-a7b8-5f4c55291800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# аугментации изображений для улучшения качества обучения\n",
    "\n",
    "augment_data = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"), # отражение по вертикали или горизонтали\n",
    "  layers.RandomRotation(0.5, fill_mode='reflect'), # поворот по часовой стрелке на случайный угол\n",
    "  layers.RandomTranslation(0.2,0.2, fill_mode=\"reflect\"), # сдвиг изображения по вертикали или горизонтали\n",
    "  layers.RandomZoom(0.3,0.3, fill_mode=\"reflect\") # случайное приближение изображения\n",
    "], name='augment_part')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59380ee-e257-4ecd-bd8f-bbd878fd9396",
   "metadata": {},
   "source": [
    "### Архитектура модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9acbedd-a421-4602-a3d8-1a6f2350bee6",
   "metadata": {},
   "source": [
    "#### Медель + слои аугментации и слои предобработки\n",
    "##### Слои аугментации используются в рантайме только во време обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d05e91-d136-405f-968b-eeadb76b4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно resize_and_rescale и augment_data не делать частью модели\n",
    "# а применить к датасетам train_ds, val_ds, test_ds\n",
    "# вопросики в столбце Output Shape - норма (тк размер входного слоя не указан)\n",
    "# размер станет известен после обучения модели\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # Add the preprocessing layers you created earlier.\n",
    "    rescale,\n",
    "    augment_data,\n",
    "    layers.Conv2D(32, (3,3), 1, activation='relu',),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, (3,3), 1, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, (3,3), 1, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(16, (3,3), 1, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='selu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='selu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05104a2f-a75d-43de-9964-8db6e4eb7c8e",
   "metadata": {},
   "source": [
    "### Пример предобработанного и аугментированного изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b91f49-846b-42d9-92dd-4bff970d7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE = 15\n",
    "fig, axes = plt.subplots(1,2)\n",
    "\n",
    "fig.set_figwidth(22)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "# read image\n",
    "img = list(train_ds)[0][0][0]\n",
    "axes[0].imshow(tf.keras.utils.array_to_img(img))\n",
    "axes[0].set_title(f\"Пример размытого изображения\", fontsize=FONT_SIZE, pad=15)\n",
    "\n",
    "# augmentate image\n",
    "img = augment_data(tf.expand_dims(img, axis=0))[0]\n",
    "axes[1].imshow(tf.keras.utils.array_to_img(img))\n",
    "axes[1].set_title(f\"Пример аугментированного размытого изображения\", fontsize=FONT_SIZE, pad=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5f5c8-468a-4d62-90c8-71a39d15be3c",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217523e-eb95-4789-9ee8-57c8873754e2",
   "metadata": {},
   "source": [
    "#### Колбэк функции для вызова в процессе обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7220e8b-01de-4821-a872-6b9488f0b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [] # массив колбэков до подачи в колбек \"callbacklist\"\n",
    "\n",
    "# если модель плохо учится - остановит обучение\n",
    "callback_list.append(keras.callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss', \n",
    "            min_delta = 0.0001, \n",
    "            patience = 3,\n",
    "            restore_best_weights = True\n",
    "            ))\n",
    "\n",
    "# если модель не учится - уменьшит шаг LEARNING_RATE\n",
    "callback_list.append(keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = 'loss', \n",
    "            factor = 0.2, \n",
    "            patience = 2, \n",
    "            verbose = 1,\n",
    "            mode = 'auto', \n",
    "            min_delta = 0.001, \n",
    "            cooldown = 2, \n",
    "            min_lr = 0\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b98bbf-5f00-40fe-b9e9-3ae182ee7673",
   "metadata": {},
   "source": [
    "#### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098e3f3-d58f-4abf-bb89-71145a207354",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    batch_size = BATCH_SIZE, \n",
    "                    epochs = 30, \n",
    "                    verbose = 1, \n",
    "                    validation_data = val_ds, \n",
    "                    callbacks = callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32324348-eaae-4738-9764-0bfcfe440064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# итоговый размер модели\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067f4cf-08a6-418c-b660-796ac6678f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE = 15\n",
    "for key in [k for k in history.history.keys() if not k.startswith('val')]:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    fig.set_figwidth(12)\n",
    "    fig.set_figheight(8)\n",
    "    \n",
    "    plt.plot(history.history[key], \n",
    "             label='Train dataset',  linewidth=1.5, color='blue')\n",
    "    if key != 'learning_rate':\n",
    "        plt.plot(history.history[f'val_{key}'], linestyle = '--', \n",
    "             label='Validation dataset',  linewidth=3, color='red')\n",
    "    \n",
    "    ax.set_xlabel('Epoch number', fontsize=FONT_SIZE)\n",
    "    ax.set_ylabel(f'{key} value', fontsize=FONT_SIZE)\n",
    "    ax.set_title(f\"Learning process {key} plot\", fontsize=FONT_SIZE, pad=15)\n",
    "    \n",
    "    ax.patch.set_alpha(0)\n",
    "    \n",
    "    #  Устанавливаем форматирование делений:\n",
    "    ax.tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "    \n",
    "    # Вывод и настройка сетки\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='major', linewidth=2)\n",
    "    ax.grid(which='minor', color = 'gray', linestyle = ':')\n",
    "    \n",
    "    ax.legend(fontsize = FONT_SIZE, facecolor = \"white\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5bab9-3005-42a3-887d-0acc27b471c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тестирование модели и итоговые значения метрик на всех выборках\n",
    "train_res = model.evaluate(train_ds, batch_size = BATCH_SIZE, verbose=0, return_dict=True)\n",
    "val_res = model.evaluate(val_ds, batch_size = BATCH_SIZE, verbose=0, return_dict=True)\n",
    "test_res = model.evaluate(test_ds, batch_size = BATCH_SIZE, verbose=0, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241bf92-5612-4d64-943c-16a804a79e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('|'*8,'train','|'*8)#,'\\n',train_res,'\\n')\n",
    "print(*[(key,value) for (key,value) in train_res.items()],sep='\\n')\n",
    "print()\n",
    "print('|'*8,'val','|'*8)#,'\\n',train_res,'\\n')\n",
    "print(*[(key,value) for (key,value) in val_res.items()],sep='\\n')\n",
    "print()\n",
    "print('|'*8,'test','|'*8)#,'\\n',train_res,'\\n')\n",
    "print(*[(key,value) for (key,value) in test_res.items()],sep='\\n')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d140e344-6fc7-4503-88ba-58ec4e189e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранения модели по желанию\n",
    "#model.save(f'model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
